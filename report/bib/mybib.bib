@misc{Drunge,
  author  = {{Daniel Runge Petersen}},
  url     = {https://github.com/AAU-Dat/templates},
  title   = {AAU-Dat templates},
  urldate = {2022-08-17}
}

@misc{Projectmodule,
  organization = {Aalborg University},
  url          = {https://moduler.aau.dk/course/2022-2023/DSNDATB521},
  title        = {Theory-driven Data Analysis and Modeling},
  urldate      = {2022-09-27}
}

@misc{IBM-machine-intelligence,
  organization = {IBM},
  url          = {https://www.ibm.com/cloud/learn/machine-learning},
  title        = {Machine Learning},
  urldate      = {2022-09-27}
}

@misc{IBM-computer-vision,
  organization = {IBM},
  url          = {https://www.ibm.com/topics/computer-vision},
  title        = {What is computer vision?},
  urldate      = {2022-09-27}
}

@misc{ml-pipeline-javapoint,
  organization = {javapoint},
  url          = {https://www.javatpoint.com/machine-learning-pipeline},
  title        = {Machine Learning Pipeline},
  urldate      = {2022-10-04}
}

@misc{lecun-mnist-database,
  organization = {Yann LeCun},
  url          = {http://yann.lecun.com/exdb/mnist/},
  title        = {MNIST database},
  urldate      = {2022-10-04}
}

@misc{fashion-mnist,
  organization = {Zalando Research},
  url          = {https://github.com/zalandoresearch/fashion-mnist},
  title        = {Fashion-MNIST},
  urldate      = {2022-10-31}
}

@misc{krizhevsky-cifar,
  organization = {Alex Krizhevsky},
  url          = {https://www.cs.toronto.edu/~kriz/cifar.html},
  title        = {CIFAR-10 and CIFAR-100},
  urldate      = {2022-10-31}
}

@article{linear-dimensionality-reduction-insights,
  title     = {Linear dimensionality reduction: Survey, insights, and generalizations},
  author    = {Cunningham, John P and Ghahramani, Zoubin},
  journal   = {The Journal of Machine Learning Research},
  volume    = {16},
  number    = {1},
  pages     = {2859--2900},
  year      = {2015},
  publisher = {JMLR. org}
}

@article{dimensionality-reduction-comparative-review,
  author  = {van der Maaten, Laurens and Postma, Eric and Herik, H.},
  year    = {2007},
  month   = {01},
  title   = {Dimensionality Reduction: A Comparative Review},
  volume  = {10},
  journal = {Journal of Machine Learning Research - JMLR}
}

@misc{decoster-1998-factor-analysis-overview,
  title     = {Overview of factor analysis},
  author    = {DeCoster, Jamie},
  year      = {1998},
  publisher = {Tuscaloosa, AL}
}

@article{lee-1999-learning-nmf,
  title     = {Learning the parts of objects by non-negative matrix factorization},
  author    = {Lee, Daniel D and Seung, H Sebastian},
  journal   = {Nature},
  volume    = {401},
  number    = {6755},
  pages     = {788--791},
  year      = {1999},
  publisher = {Nature Publishing Group}
}

@misc{Stochastic-optimization-neural-networks-assiri,
  author  = {Yahia Saeed Assiri},
  url     = {https://arxiv.org/ftp/arxiv/papers/2001/2001.08856.pdf},
  title   = {Stochastic Optimization of Plain Convolutional Neural Networks with Simple methods},
  urldate = {2022-10-11}
}
@article{BYERLY2021545,
  title  = {No routing needed between capsules},
  year   = {2021},
  issn   = {0925-2312},
  doi    = {https://doi.org/10.1016/j.neucom.2021.08.064},
  url    = {https://www.sciencedirect.com/science/article/pii/S0925231221012546},
  author = {Adam Byerly and Tatiana Kalganova and Ian Dear}
}
@misc{convolutional-neural-networks-convnets,
  doi    = {10.48550/ARXIV.2008.10400},
  url    = {https://arxiv.org/abs/2008.10400},
  author = {An, Sanghyeon and Lee, Minjun and Park, Sanglee and Yang, Heerin and So, Jungmin},
  title  = {An Ensemble of Simple Convolutional Neural Network Models for MNIST Digit Recognition},
  year   = {2020}
}
@inproceedings{multi-column-neural-network-ciregan,
  author = {Ciregan, Dan and Meier, Ueli and Schmidhuber, Jürgen},
  title  = {Multi-column deep neural networks for image classification},
  year   = {2012},
  doi    = {10.1109/CVPR.2012.6248110}
}
@misc{WaveMix-jeevan,
  doi    = {10.48550/ARXIV.2205.14375},
  url    = {https://arxiv.org/abs/2205.14375},
  author = {Jeevan, Pranav and Viswanathan, Kavitha and Sethi, Amit},
  title  = {WaveMix-Lite: A Resource-efficient Neural Network for Image Analysis},
  year   = {2022}
}
@misc{MnistStatictics,
  organization = {Paperswithcode},
  url          = {https://paperswithcode.com/sota/image-classification-on-mnist},
  title        = {Image Classification on MNIST},
  urldate      = {2022-10-11}
}
@misc{WhatIsLogisticRegression,
  organization = {IBM},
  url          = {https://www.ibm.com/topics/logistic-regression},
  title        = {What is logistic regression?},
  urldate      = {2022-10-11}
}
@misc{SupervisedLearning,
  organization = {IBM},
  url          = {https://www.ibm.com/cloud/learn/supervised-learning},
  title        = {Supervised learning},
  urldate      = {2022-10-11}
}
@misc{LogisticRegressionProsAndCons,
  organization = {Medium},
  url          = {https://medium.datadriveninvestor.com/logistic-regression-essential-things-to-know-a4fe0bb8d10a},
  title        = {Logistic Regression: Essential Things to Know},
  urldate      = {2022-10-11}
}
@misc{K-NearestNeighborsIBM,
  organization = {IBM},
  url          = {https://www.ibm.com/topics/knn#:~:text=The%20k%2Dnearest%20neighbors%20algorithm%2C%20also%20known%20as%20KNN%20or,of%20an%20individual%20data%20point},
  title        = {K-Nearest Neighbors Algorithm},
  urldate      = {2022-10-11}
}
@misc{SupportVectorMachines,
  organization = {Towards Data Science},
  url          = {https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47},
  title        = {Support Vector Machine — Introduction to Machine Learning Algorithms},
  urldate      = {2022-10-11}
}
@misc{SVMProsAndCons,
  organization = {Roboticsbiz},
  url          = {https://roboticsbiz.com/pros-and-cons-of-support-vector-machine-svm/},
  title        = {Pros And Cons Of Support Vector Machine (SVM)},
  urldate      = {2022-09-10}
}
@misc{CNNIBM,
  organization = {IBM},
  url          = {https://www.ibm.com/cloud/learn/convolutional-neural-networks},
  title        = {How do convolutional neural networks work?},
  urldate      = {2022-10-11}
}
@misc{CNNProsAndCons,
  organization = {GeeksforGeeks},
  url          = {https://www.geeksforgeeks.org/difference-between-ann-cnn-and-rnn/},
  title        = {Difference between ANN, CNN and RNN},
  urldate      = {2022-10-11}
}

@article{non-negative-matrix-factorization,
  title   = {The why and how of nonnegative matrix factorization},
  author  = {Gillis, Nicolas},
  journal = {Connections},
  volume  = {12},
  number  = {2},
  year    = {2014}
}

@article{linear-discriminant-analysis-tutorial,
  title     = {Linear discriminant analysis: A detailed tutorial},
  author    = {Tharwat, Alaa and Gaber, Tarek and Ibrahim, Abdelhameed and Hassanien, Aboul Ella},
  journal   = {AI communications},
  volume    = {30},
  number    = {2},
  pages     = {169--190},
  year      = {2017},
  publisher = {IOS Press}
}

@misc{kernel-pca,
  doi    = {10.48550/ARXIV.1207.3538},
  url    = {https://arxiv.org/abs/1207.3538},
  author = {Wang, Quan},
  title  = {Kernel Principal Component Analysis and its Applications in Face Recognition and Active Shape Models},
  year   = {2012}
}

@misc{tennenbaum,
  url     = {https://wearables.cc.gatech.edu/paper_of_week/isomap.pdf},
  title   = {A Global Geometric Framework for Nonlinear Dimensionality Reduction},
  author  = {Joshua B. Tennenbaum, Vin de Silva, John C. Langford},
  urldate = {2022-10-11}
}

@misc{multi-dimensional-scaling-and-isomap,
  doi       = {10.48550/ARXIV.2009.08136},
  url       = {https://arxiv.org/abs/2009.08136},
  author    = {Ghojogh, Benyamin and Ghodsi, Ali and Karray, Fakhri and Crowley, Mark},
  title     = {Multidimensional Scaling, Sammon Mapping, and Isomap: Tutorial and Survey},
  publisher = {arXiv},
  year      = {2020}
}

@misc{difference-between-pca-and-mds,
  url     = {https://stats.stackexchange.com/questions/14002/whats-the-difference-between-principal-component-analysis-and-multidimensional},
  title   = {What's the difference between principal component analysis and multidimensional scaling?},
  urldate = {2022-10-11}
}

@article{rifkin-defense-one-vs-all,
  title     = {In defense of one-vs-all classification},
  author    = {Rifkin, Ryan and Klautau, Aldebaro},
  journal   = {The Journal of Machine Learning Research},
  volume    = {5},
  pages     = {101--141},
  year      = {2004},
  publisher = {JMLR. org}
}

@book{james-statistical-learning,
  added-at  = {2019-10-12T20:03:56.000+0200},
  author    = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  biburl    = {https://www.bibsonomy.org/bibtex/2444186c86d18bddb4433c12fa126f6be/lopusz_kdd},
  interhash = {b3febabdc45a8629023cee7323dfbd86},
  intrahash = {444186c86d18bddb4433c12fa126f6be},
  keywords  = {general_machine_learning},
  publisher = {Springer},
  timestamp = {2019-10-12T23:45:37.000+0200},
  title     = {An Introduction to Statistical Learning: with Applications in R },
  url       = {https://faculty.marshall.usc.edu/gareth-james/ISL/},
  year      = 2013
}

@misc{metrics-for-multi,
  doi       = {10.48550/ARXIV.2008.05756},
  url       = {https://arxiv.org/abs/2008.05756},
  author    = {Grandini, Margherita and Bagli, Enrico and Visani, Giorgio},
  keywords  = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Metrics for Multi-Class Classification: an Overview},
  publisher = {arXiv},
  year      = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Unreasonable-effectiveness-of-data-Norvig,
  author  = {Halevy, Alon and Norvig, Peter and Pereira, Fernando},
  title   = {The Unreasonable Effectiveness of Data},
  year    = {2009},
  doi     = {10.1109/MIS.2009.36}
}
@misc{data-never-sleeps,
year={2022},
month={Sep 21},
title={Domo Releases 10th Annual “Data Never Sleeps” Infographic},
url={https://www.proquest.com/wire-feeds/domo-releases-10th-annual-data-never-sleeps/docview/2716042192/se-2%7D},
}

@book{Feature-engineering-zheng,
author = {Zheng, Alice and Casari, Amanda},
title = {Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists},
year = {2018},
isbn = {1491953241},
}

@article{imputation-for-tables-Biessmann,
  author  = {Felix Biessmann and Tammo Rukat and Phillipp Schmidt and Prathik Naidu and Sebastian Schelter and Andrey Taptunov and Dustin Lange and David Salinas},
  title   = {DataWig: Missing Value Imputation for Tables},
  year    = {2019},
  url     = {http://jmlr.org/papers/v20/18-753.html}
}

@article{outlier-perez,
author = {Perez, Husein and Tah, Joseph H. M.},
title = {Improving the Accuracy of Convolutional Neural Networks by Identifying and Removing Outlier Images in Datasets Using t-SNE},
year = {2020},
url = {https://www.mdpi.com/2227-7390/8/5/662},
ISSN = {2227-7390},
DOI = {10.3390/math8050662}
}

@book{nonlinear-dim-red-chapter-one,
author={Lee, John A. and Verleysen, Michel},
title={High-Dimensional Data},
bookTitle={Nonlinear Dimensionality Reduction},
year={2007},
isbn={978-0-387-39351-3},
doi={10.1007/978-0-387-39351-3_1},
url={https://doi.org/10.1007/978-0-387-39351-3_1}
}


@article{dimensionality-reduction-reddy,
  author={Reddy, G. Thippa and Reddy, M. Praveen Kumar and Lakshmanna, Kuruva and Kaluri, Rajesh and Rajput, Dharmendra Singh and Srivastava, Gautam and Baker, Thar},
  journal={IEEE Access}, 
  title={Analysis of Dimensionality Reduction Techniques on Big Data}, 
  year={2020},
  doi={10.1109/ACCESS.2020.2980942}}

@article{dimensionality-reduction-cheng,
author = {Cheng, Zhun and Lu, Zhixiong},
year = {2018},
title = {A Novel Efficient Feature Dimensionality Reduction Method and Its Application in Engineering},
journal = {Complexity},
doi = {10.1155/2018/2879640}
}

@article{dimensionality-reduction-maitra,
  author={Maitra, Shithi and Hossain, Tonmoy and Hasib, Khan Md. and Shishir, Fairuz Shadmani},
  title={Graph Theory for Dimensionality Reduction: A Case Study to Prognosticate Parkinson's}, 
  year={2020},
  doi={10.1109/IEMCON51383.2020.9284926}}

@misc{dim-red-visual,
title={{Dimensionality reduction for visual exploration of similarity structures}},
author={Venna, Jarkko},
year={2007},
language={English},
pages={81, [115]},
publisher={Helsinki University of Technology},
type={Doctoral thesis},
keywords={dimensionality reduction, exploratory data analysis, information retrieval, information visualization, manifold learning, Markov Chain Monte Carlo},
isbn={978-951-22-8752-9},
series={Dissertations in computer and information science. Report D; 20},
issn={1459-7020},
url={}
}

@book{nonlinear-dim-red-chapter-one,
author="Lee, John A.
and Verleysen, Michel",
editor="Lee, John A.
and Verleysen, Michel",
title="High-Dimensional Data",
bookTitle="Nonlinear Dimensionality Reduction",
year="2007",
publisher="Springer New York",
address="New York, NY",
pages="1--16",
isbn="978-0-387-39351-3",
doi="10.1007/978-0-387-39351-3_1",
url="https://doi.org/10.1007/978-0-387-39351-3_1"
}

@book{nonlinear-dim-red-chapter-two,
author="Lee, John A.
and Verleysen, Michel",
editor="Lee, John A.
and Verleysen, Michel",
title="Characteristics of an Analysis Method",
bookTitle="Nonlinear Dimensionality Reduction",
year="2007",
publisher="Springer New York",
address="New York, NY",
pages="17--45",
isbn="978-0-387-39351-3",
doi="10.1007/978-0-387-39351-3_2",
url="https://doi.org/10.1007/978-0-387-39351-3_2"
}

@book{nonlinear-dim-red-chapter-three,
author="Lee, John A.
and Verleysen, Michel",
editor="Lee, John A.
and Verleysen, Michel",
title="Estimation of the Intrinsic Dimension",
bookTitle="Nonlinear Dimensionality Reduction",
year="2007",
publisher="Springer New York",
address="New York, NY",
pages="47--67",
isbn="978-0-387-39351-3",
doi="10.1007/978-0-387-39351-3_3",
url="https://doi.org/10.1007/978-0-387-39351-3_3"
}
