\section{Linear versus nonlinear methods}\label{sec:linear-vs-nonlinear} 

This section will explore dimensionality reduction more. More specifically, this project will distinguish between linear and nonlinear methods. According to John A. Lee~\cite{nonlinear-dim-red-chapter-two}, several distinctions can be made for dimensionality reduction methods. This project will only focus on one distinction from \cite{nonlinear-dim-red-chapter-two}, linear and nonlinear because it is the most straightforward way of classifying dimensionality reduction. It is essential to distinguish between methods to classify them and to understand their differences. This will help to understand the advantages and disadvantages of each method. This will also help to understand which method is the most suitable for a specific problem~\cite{nonlinear-dim-red-chapter-two}. The following section will discuss the differences between linear and nonlinear methods. 


\subsection{Results and differences of linear and nonlinear methods}

As outlined earlier, dimensionality reduction methods can be used to remove redundancy from data, which can improve the performance of a \gls{ml} model. However, the methods can also be used for other purposes, such as visualization and feature engineering~\cite{nonlinear-dim-red-chapter-two}.
A linear method assumes linear independence of the features. Linear independence means that the features are independent of each other; this is a strong assumption, which is only sometimes true~\cite{linear-algebra-margalit}. A nonlinear method does not assume linear independence of the features, which means that the features are not independent; this is a weaker assumption, which is often true~\cite{avriel2003nonlinear}. That means that a nonlinear method is often more robust than a linear method. However, a nonlinear method requires more parameters, which can require more data in a model~\cite{nonlinear-dim-red-chapter-two}.

Examples of how linear and nonlinear dimensionality reduction methods can be used can be seen in~\cite{dimensionality-reduction-comparative-review, tennenbaum}, where the methods have been tested on artificial and real-world datasets. As an example, it has shown that artificial datasets, such as the swiss-roll, show that linear methods have a more challenging time finding the intrinsic dimensionality of the data than nonlinear methods~\cite{tennenbaum}.

The research paper~\cite{dimensionality-reduction-comparative-review} compares the performance of linear and nonlinear dimensionality reduction methods with some \gls{ml} models. 

According to Laurens~\cite{dimensionality-reduction-comparative-review}, there is a tendency for real-world data to be nonlinear. The linear methods should have a disadvantage because they cannot capture the intrinsic dimensionality of the nonlinear data and nonlinear methods. However, the research paper states that nonlinear methods can only sometimes outperform linear methods~\cite{dimensionality-reduction-comparative-review}.  

In this project, the focus will be on whether linear or nonlinear methods positively impact the performance of the \gls{ml} model implemented in this project. The differences between the methods used in this project will be presented in section~\ref{sec:dimensionality-reduction}.

%Jarkko shows that linear and nonlinear dimensionality reduction methods can be visualized on separate datasets~\cite{dim-red-visual}, and visualization can aid in analyzing which methods are better than others at finding an accurate lower representation of the data. 
 
%This project will focus on the dichotomy between linear and nonlinear methods and how they each affect the data. There will also be a focus on specifically the computational gains possible with these methods and how they handle different kinds of data.
%we want to explore whether these methods have a significant influence on the performance of a machine learning model~\cite{dimensionality-reduction-reddy,dimensionality-reduction-comparative-review}.

% In this section we have presented a short overview of the dimensionality reduction methods, i.e. linear and nonlinear methods. We have also presented some applications of the methods, and provided a reason for why we want to explore the methods in the project.

