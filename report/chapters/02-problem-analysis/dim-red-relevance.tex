\section{Linear versus nonlinear methods}\label{sec:linear-vs-nonlinear} \todo[inline]{Is the nonlinear vs linear classification yours? or does it need a reference? Why is that classification important? and why not use Lees?}

In this section we will explore dimensionality reduction more. More specifically, in this project we will distinguish between linear and nonlinear methods. According to John A. Lee, there are several distinctions that can be made for dimensionality reduction methods\cite{nonlinear-dim-red-chapter-two}. We will not focus on them, but will choose to classify them as linear and nonlinear because it is the most straightforward way of classifying them. Nonlinear methods are much more complex than the linear ones, and also more computationally expensive~\cite{nonlinear-dim-red-chapter-two}. The details regarding the difference between the methods will be presented in section~\ref{sec:dimensionality-reduction}.

\subsection{Applications of dimensionality reduction methods}\todo[inline]{This section should be included before}

Dimensionality reduction has many different applications, and for different applications, different methods can prove to be more suitable. In this section we will discuss some of the most common applications of dimensionality reduction methods. An example of the applications of dimensionality reduction, can be seen in \cite{sarwar2000application}, that discusses the use of dimensionality reduction in recommender systems. Using dimensionality reduction methods to help the scalability of the system by reducing the amount of data run on the system, and also to improve the quality of the recommendations. Additionally, dimensionality reduction can also be used in applications, such as image compression, visualization of high dimensional data, and feature extraction. Showing that is has many different applications, and that it is a very useful tool.


\subsection{Results and differences of linear and nonlinear methods}\todo[inline]{When do you define what linear and nonlinear are?According to this section are there good reasons to use nonlinear methods? Remind me of this during the meeting}

The use of the linear and nonlinear dimensionality reduction methods can among others be seen in~\cite{dimensionality-reduction-comparative-review, tennenbaum}, where the methods have been tested on artificial and real-world datasets. As an example, it is shown that artificial datasets such as the swiss-roll, show that linear methods fail to find the intrinsic dimensionality of the data, as opposed to nonlinear methods~\cite{tennenbaum}.

Jarkko shows that linear and nonlinear dimensionality reduction methods can be visualized on separate datasets~\cite{dim-red-visual}, and visualization can provide an aid at analyzing which methods are better than others at finding an accurate lower representation of the data. The research paper~\cite{dimensionality-reduction-comparative-review} compares the performance of linear and nonlinear dimensionality reduction methods with some machine learning model.

According to Laurens, there is a tendency that the real world data is nonlinear. This means that the linear methods are at disadvantage, because they are not able to capture the intrinsic dimensionality of the nonlinear data, as good as nonlinear methods. However, he also states that nonlinear methods are not always able to outperform linear methods~\cite{dimensionality-reduction-comparative-review}, which might be seen as counterintuitive, since nonlinear methods are supposed to outperform linear methods on nonlinear data.


\subsection{Relevance of linear vs nonlinear methods} \todo[inline]{This section could be tied to the previous one}

%This project will focus on the dichotomy between linear and nonlinear methods and how they each affect the data. There will also be a focus on specifically the computational gains possible with these methods and how they handle different kinds of data.
%we want to explore whether these methods have a significant influence on the performance of a machine learning model~\cite{dimensionality-reduction-reddy,dimensionality-reduction-comparative-review}.
As outlined ealier, dimensionality reduction methods can be used to remove redundancy from data, which can improve the performance of a machine learning model. We have presented that nonlinear methods may work better on nonlinear datasets, and that they are suitable for nonlinear datasets, but according to Laurens~\cite{dimensionality-reduction-comparative-review}, there might not be a major difference between the linear and nonlinear methods. That is why we want to explore whether linear or nonlinear methods \textit{actually} have the most positive impact on our machine learning model.




% In this section we have presented a short overview of the dimensionality reduction methods, i.e. linear and nonlinear methods. We have also presented some applications of the methods, and provided a reason for why we want to explore the methods in the project.

