\chapter{Problem analysis}\label{cha:problem-analysis}
This chapter describes the motivation for the project, culminating in a problem statement.

\begin{itemize}
    \item Why Machine learning + Generalized pipeline overview?
    \item Why Feature Engineering: Dimensionality reduction
          \begin{itemize}
              \item Extraction
              \item Visualization
              \item Learning/debugging
          \end{itemize}
    \item Linear versus nonlinear methods
    \item Problem statement
\end{itemize}

\gls{ml} is a field of study within \gls{ai} concerned with learning from data. \gls{ml} is a complex and growing field used in many areas. One of the reasons for the increasing interest in \gls{ml} is the increasing amount of available data. The amount of data collected in the world is increasing at an incredible rate, which is expected to continue in the future~\cite{data-never-sleeps}. Because \gls{ml} models are trained on data, the more data available, the better the models can be~\cite{Unreasonable-effectiveness-of-data-Norvig}.

\gls{ml} can very generally be described as the discipline teaching computers achieve task that where no perfect algorithm is possible. This also covers when there are many possible good ways to achieve something then some of those are then labeled as acceptable ways to succeed. These answers are then used to "train" the computer to improve on some basic algorithm. \todo{need to fix source}(Ethem Alpaydin (2020). Introduction to Machine Learning (Fourth ed.)) Inside a field as complex as \gls{ml} there exist many challengens one such challenge is working with High-dimensional data. This is due to the inherint properties of many dimensions which makes it difficult to interpret and also computationally expensive. Higher dimensions are also associated with the so called "curse of dimensionality". This term was coined by Richard E. Bellman in a paper about dynamic programming (Bellman, Richard Ernest; Rand Corporation (1957). Dynamic programming). This tearm is used interchangedly with the tearms peaking phenomenon and Hughes phenomenon.(Koutroumbas, Konstantinos; Theodoridis, Sergios (2008).)(Hughes, G.F. (January 1968). "On the mean accuracy of statistical pattern recognizers"). McLachlan described, states that (McLachlan, 2004, p. 391): \todo{proper sources}
“For training samples of a ﬁnite size, the performance of a given discriminant
rule in a frequentist framework does not keep on improving as the number p
of feature variables is increased. Rather, its overall unconditional error rate
will stop decreasing and start to increase as pis increased beyond a certain
threshold.”.
These difficulties associated with data in many dimensions makes the study of methods to reduce dimensions or dimensionality reduction highly relevant. Dimensionality reduction is a very diverse topic, it will be  explained what it is and some of its uses in the following paragraphs.

% The most usual methods of dimensionality reduction are linear methods. These
% methods might assume that the features in the original data are independent and
% they can produce reduced data by a linear combination of the original data. These
% assumptions might not apply to all datasets. In fact, there are cases in which linear
% methods do not capture important features of a dataset. For these cases one can
% use nonlinear methods/ These methods can be used for more general cases while
% preserving important information from data



% However the complexity of \gls{ml} is also high. There are many different \gls{ml} models, each with different strengths and weaknesses. The choice of \gls{ml} model is therefore more often than not dependent on the data and the problem being solved. This means that choosing the right \gls{ml} model is a difficult task, which is further complicated by the fact that there is no single metric for evaluating the performance of a \gls{ml} model. The performance of a \gls{ml} model is often evaluated using multiple metrics, which makes it difficult to compare the performance of different models against each other.

% It may be necessary to try out different \gls{ml} models to find the best one for a certain problem, which is a time-consuming process.

\input{chapters/02-problem-analysis/feature-engineering.tex}
\input{chapters/02-problem-analysis/dim-red-relevance.tex}

\input{chapters/02-problem-analysis/machine-learning.tex}
\input{chapters/02-problem-analysis/problem-statement.tex}