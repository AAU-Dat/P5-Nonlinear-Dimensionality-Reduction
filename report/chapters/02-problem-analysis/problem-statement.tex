\section{Problem Statement}\label{sec:problem-statement}

\newacronym{cnn}{CNN}{Convolutional Neural Network}
\newacronym{mnist}{MNIST}{Modified National Institute of Standards and Technology}
\newacronym{nn}{NN}{Neural Network}
\newacronym{ml}{ML}{Machine Learning}

This project explores the impact of data preproccesing on the performance of machine learning using a logistic regression model versus \gls{cnn} for the computer vision problem of image classification and recognition. The data preprocessing is done through dimensionality reduction on augmented data from the \gls{mnist} database, and the machine learning models are trained on the reduced data. The performance metrics used to evaluate the models are accuracy, precision, recall, and F1 score\question{Or something else? Placeholder metrics}. and of course explainability and speed/size of the models.

\subsection{Tools}\label{subsec:tools}
Data preproccessing, data augmentation and feature engineering

Use Keras to build a \gls{ml} model.

Computer vision

Explainability - \gls{nn} vs other \gls{ml} algorithms

Humans vs computers in \gls{nn}. Why are humans good with little training, and computers only accceptable with much more training? Consider perhaps domains (recongnizing epsilon vs. recognizing a 3)

\supervisor{How do we determine recall and precision for logistic regression?}