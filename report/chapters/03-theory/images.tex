\section{Images}\label{sec:images}
% As mentioned before, the project will use the \gls{mnist} dataset; the dataset comprises images; therefore, a digital image consists of pixels. In a grayscale image, each pixel has a value between 0 and 255, where 0 is white, and 255 is black. In a color image, each pixel has three values - one for each color: red, green, and blue; the amount of pixels in a color picture is the same as in a grayscale picture. A 28x28x1 grayscale image has 784 pixels, while a 28x28x3 color image also has 784 pixels~\cite{picture}.

% In this project, dimensionality reduction is shown by each pixel representing the image's feature (dimension). As the size of images increases, this quickly becomes a large number of features.

In this project, we have chosen to work with the \gls{mnist} dataset because it is commonly used in image recognition tasks, specifically for recognizing handwritten digits. This dataset is well-documented, which allows us to compare our results to other similar projects, and it is small in size, making it easy to work with and not requiring a lot of computational power\cite{lecun-mnist-database}. Additionally, the preprocessing of the \gls{mnist} dataset has further reinforced our decision to use it.

It was considered to use the Iris and CIFAR-10 datasets, but the Iris dataset may have too few data samples \cite{mnist-vs-iris} and the CIFAR-10 dataset could be too complex for this project\cite{datasets-uniqtech}. The \gls{mnist} dataset consists of images, and each image is composed of pixels. In a grayscale image, each pixel has a value between 0 and 255, with 0 representing white and 255 representing black.

In this project aims to demonstrate dimensionality reduction by representing each pixel as a feature in the image. As the size of the images increases, this quickly becomes a large number of features.