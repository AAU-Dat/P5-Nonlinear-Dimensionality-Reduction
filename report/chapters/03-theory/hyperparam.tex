\section{Hyperparameter optimization}
%what is that
%why is that an important thing >> CHECK.
%examples perhaps on Hyperparameter optimization


Hyperparameter optimization comprises of the tuning of the machine learning model's hyperparameters. Hyperparameters are the configurations of the model that can change its behavior. Their purpose is to maximize the performance of the model, and can have varying effects on the model and its performance \cite{hyperparam-search}. Hyperparameters can, for example, be of real valued nature or categorical nature. Support Vector Machine has as parameters the number of iterations as an integer, and the kernel used as a category, where one can choose from its different kernels.


Choosing the right hyperparameters might involve manually changing them, which is time-consuming. It also leaves the responsibility to the programmer to change those values. What can be done instead, is to automate the process, leaving it to the computer to find the most optimal hyperparameters \cite{automated-machine-learning}. The reason why hyperparameter is difficult is because we do not know which hyperparameters will affect the model the most, which hyperparameters will interact with other hyperparameters and how their interactions will change the model's performance.


There are different methods by which hyperparameters can be applied.






%@book{automated-machine-learning,
% author="Feurer, Matthias
% and Hutter, Frank",
% editor="Hutter, Frank
% and Kotthoff, Lars
% and Vanschoren, Joaquin",
% title="Hyperparameter Optimization",
% bookTitle="Automated Machine Learning: Methods, Systems, Challenges",
% year="2019",
% publisher="Springer International Publishing",
% address="Cham",
% pages="3--33",
% abstract="Recent interest in complex and computationally expensive machine learning models with many hyperparameters, such as automated machine learning (AutoML) frameworks and deep neural networks, has resulted in a resurgence of research on hyperparameter optimization (HPO). In this chapter, we give an overview of the most prominent approaches for HPO. We first discuss blackbox function optimization methods based on model-free methods and Bayesian optimization. Since the high computational demand of many modern machine learning applications renders pure blackbox optimization extremely costly, we next focus on modern multi-fidelity methods that use (much) cheaper variants of the blackbox function to approximately assess the quality of hyperparameter settings. Lastly, we point to open problems and future research directions.",
% isbn="978-3-030-05318-5",
% doi="10.1007/978-3-030-05318-5_1",
% url="https://doi.org/10.1007/978-3-030-05318-5_1"
% }






% @article{hyperparam-search,
%   author    = {Marc Claesen and
%                Bart De Moor},
%   title     = {Hyperparameter Search in Machine Learning},
%   journal   = {CoRR},
%   volume    = {abs/1502.02127},
%   year      = {2015},
%   url       = {http://arxiv.org/abs/1502.02127},
%   eprinttype = {arXiv},
%   eprint    = {1502.02127},
%   timestamp = {Mon, 13 Aug 2018 16:48:58 +0200},
%   biburl    = {https://dblp.org/rec/journals/corr/ClaesenM15.bib},
%   bibsource = {dblp computer science bibliography, https://dblp.org}
% }