\section{Preprocessing}\label{sec:preprocessing}
In this section, the theory of preprocessing and what effects it has on the \gls{ml} model is discussed.


%What is preproccessing?
%What effects does it have on the model/data?
%Why do we need it?
%What are the steps?
%What are the tools?
%What are the results?

\subsection{Definition of preprocessing}\label{subsec:preprocessing-definition}
The proper definition of preprocessing or data preparation varies depending on the source. The explanation that will be used in this report is given as follows:

\textcquote{data-preparation-for-data-mining}{Data preparation comprises those techniques concerned with analyzing raw data so as to yield quality data, mainly including data collecting, data integration, data transformation, data cleaning, data reduction, and data discretization.}

From this, it can be gathered that preprocessing is a broad term that can be divided into several subcategories. Not all subcategories will be relevant to this project; therefore, the following sections will only discuss appropriate subcategories of preprocessing.
  

\subsection{Reasons for preprocessing}\label{subsec:preprocessing-reasons}
As stated in the definition, preprocessing is used, among other reasons, to yield quality data. The importance of this stems from the fact that real-world data is only sometimes clean or complete. Meaning that can be a lot of noise, which is data containing errors or outliers. This noise can be removed by preprocessing, which creates a more accurate, higher quality, and smaller dataset to gather information. This results in a reduced amount of data that the model is trained on, but the data it is trained on should be more accurate, which should then train the model more accurately and efficiently~\cite{data-preparation-for-data-mining}.


Data collected may be in a form or shape that is not compatible with the process that is needed to work with it. Therefore, to use the data, it may need to be transformed into a form that fits with the process. Transformation of data can be many things, as~\cite{Data-preprocessing-for-flight-delays} mentions normalization as a part of the transformation, to scale the data so that it fits into a new range, Subsection \ref{sec:normalization} will give a more detailed explanation of normalization.

  
  
\subsection{Steps of preprocessing}\label{subsec:preprocessing-steps}
The amount of preprocessing depends on what is needed and what is available. In the report~\cite{Data-preprocessing-for-flight-delays}, these steps are shown. 

They start by cleaning data, transforming it, reducing it, and balancing it. This section will explain the theory of the steps used in this report.

\input{chapters/03-theory/normalization.tex}
\input{chapters/03-theory/data-augmentations.tex}

% @misc{scikit-learn-PCA,
%   year = {2022},
%   month = {Nov 22},
%   title = {sklearn.decomposition.PCA},
%   url = {https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA.fit}
% }

% @article{data-preparation-for-data-mining,
%   author = { Shichao, Zhang and Chengqi, Zhang and Qiang, Yang },
%   title = {Data preparation for data mining},
%   year = {2003},
%   publisher = {Taylor & Francis},
%   doi = {10.1080/713827180},
%   url = {https://doi.org/10.1080/713827180},
% }

% @INPROCEEDINGS{Data-preprocessing-for-flight-delays,
%   author={Moreira, Leonardo and Dantas, Christofer and Oliveira, Leonardo and Soares, Jorge and Ogasawara, Eduardo},   
%   booktitle={2018 International Joint Conference on Neural Networks (IJCNN)},  
%   title={On Evaluating Data Preprocessing Methods for Machine Learning Models for Flight Delays},
%   year={2018},
%   doi={10.1109/IJCNN.2018.8489294},
% }


%Explain why this is needed, for other reasons than just making it easier to understand.
%Does scikit methods need it to be in this format?
%Easier to use a function on a single image  

%Reshape
%normalize/Scale - StandardScaler
    %Look at others
  

%focus on cleaning or dim reduction
%Is augmentation a part of preproccessing?
%What is the difference between cleaning and dim reduction?
%Transforming data to fit our current needs
  

%Data preparation comprises those techniques concerned with analyzing raw data so as to yield quality data, mainly including data collecting, data integration, data transformation, data cleaning, data reduction, and data discretization.
    %We want data preprocessing, due to real world data being incomplete, noisy, and inconsistent.
    %Generates a smaller dataset to work with, which makes it more efficient for datamining.

%https://www.frontiersin.org/articles/10.3389/fbioe.2020.00260/full
    %Data preprocessing subcategories: (1) Ground reaction force (GRF) filtering, (2) time derivative, (3) time normalization, (4) data reduction, (5) weight normalization, and (6) data scaling.
 

%https://praveenkds.medium.com/data-preparation-for-machine-learning-data-cleaning-data-transformation-data-reduction-c4c86c4471a1
    %Data cleaning: removing noise, outliers, and missing values.
    %Data transformation: scaling, normalization, and discretization.
    %Data reduction: feature selection and feature extraction.