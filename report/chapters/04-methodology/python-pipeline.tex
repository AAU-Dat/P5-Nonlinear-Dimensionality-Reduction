\tikzstyle{circle} = [ellipse, minimum width=1.5cm, minimum height=0.5cm, text centered, draw=black, fill=white!30]
\section{Python pipeline}\label{sec:python-pipeline}
The python pipeline is based on the model in Figure~\ref{fig:python-pipeline-model}. The pipeline is divided into 5 tasks, which are described in the following sections. 

\begin{figure}[htb!]
    \centering
    \input{figures/python-pipeline.tex}
    \caption{Python pipeline}
    \label{fig:Python-pipeline}
\end{figure}

An overview of the pipeline can be seen in Figure~\ref{fig:Python-pipeline}. The pipeline is divided into 5 tasks, which are described in the following sections. 

 
The first task is loading the \gls{mnist} data set. The data set is divided into three subsets: the training, validation, and test sets. 
The model trains with the training set, tunes the hyperparameters with the validation set and evaluates the test set. Two kinds of data sets can be chosen: the original \gls{mnist} data set or an augment \gls{mnist} data set, which will be presented after this figure. 

The second task is pre-processing the data. This is done by rescaling the image or making the image only black and white because the chosen data set can be the augmented set, which already has some noise in the image. This task can be optional to make it harder for the model to learn the data.

The third task is dimensionality reduction, where the data's dimensions can be reduced. The motive for not reducing the data is the need to have the model's base metrics without any dimensionality reduction; in that way, a comparison between the base model and model with the different dimensionality reduction methods can be presented regarding their results.

The fourth task is the machine learning model, which trains the model with the chosen reduced or original train data set depending on previous choices. 
To not overfit the machine learning model, cross-validation is implemented.
The model trains with the training set and validation set, and the test results are then evaluated and compared to the results of the other models. The evaluation is done by explainability, accuracy, precision, recall, f1-score, speed/run time, and memory usage.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The first task is the dataset the dataset is the \gls{mnist} data set. The data set is divided into 3 subsets, which are the training set, the validation set, and the test set. The training set is used to train the model, the validation set is used to tune the hyperparameters of the model, and the test set is used to evaluate the model. There can be chosen two kinds of data sets, the original \gls{mnist} data set or an argumented \gls{mnist} data-set, which will be presented after this figure. 

Thd second task is pre-processing the data. This is done by rescaling the image or making the image only black and white because the chosen data set can be the argumented set, which already has some noice in the image. This task can be optional as to make it harder for the model to learn the data.

The third task is in dimensionality reduction where it is decided if the data should be reduced or not and what type of dimensionality reduction should be made linear or non linear. The fourth task is in the machine learning model where the model is trained with the chosen reduced or original train data-set depending on previous choises. When the model is trained, it is tested on the test data. The results of the test is then evaluated and can compared to the results of the other models. The evaluation is done by explainability, accuracy, precision, recall, f1-score, speed/run time, and memory usage.

\begin{figure}[htb!]
    \centering
    \input{figures/data-argumentation.tex}
    \caption{Data argumentation creation}
    \label{fig:data-argumentation-create}
\end{figure}

In Figure~\ref{fig:data-argumentation-create} the data argumentation is visualized. The pipeline is divided into 3 tasks. The first task is in data argumentation where it is decided what type of argumentation is used. This can be blur, rotation, noise, or a combination of these. The second task is then to use the argumentation on the MNIST data-set. Where we get the argumented MNIST data-set, which will be the input to the machine learning model. A side note is the size of the argumented data-set can be bigger than the original MNIST data-set.

\begin{figure}[htb!]
    \centering
    \input{figures/data-separation.tex}
    \caption{Data-set separation}
    \label{fig:data-set-sepa}
\end{figure}

In Figure~\ref{fig:data-set-sepa} describes how the data-set from MNIST will be devided. It will be devided into two data-sets, one for training and one for testing. The training data-set will be used to train the machine learning model. The default size is 80\% for training and 20\% for testing.