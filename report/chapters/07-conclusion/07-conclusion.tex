\chapter{Conclusion}\label{cha:conclsvmusion}
Based on the discussion in chapter \ref{cha:discussion}, the results from chapter \ref{cha:results} and the problem statement in section \ref{sec:problem-statement}, we conclude:


In this project, we aimed to explore the impact of dimensionality reduction on the performance of a \gls{ml} for image classification and recognition. We focused on comparing linear and non-linear dimensionality reduction techniques on \gls{mnist}, using a \gls{svm} as our model of choice. Our results showed that, for sample sizes greater than 2000, linear dimensionality reduction techniques were generally faster than nonlinear methods, while achieving similar levels of accuracy. This supports our hypothesis "nonlinear dimensionality reduction methods work as well as linear methods on the \gls{mnist} dataset". However, our results also indicated that nonlinear methods were more robust, in that they could remove more components before a significant drop in accuracy occurred. Overall, our findings support our hypothesis and provide valuable insights into the relative effectiveness of different dimensionality reduction techniques for image classification tasks.

In conclusion, our project has provided valuable insights into the use of dimensionality reduction techniques in image classification and recognition tasks. We have shown that, while non-linear methods may be more computationally expensive, they can be equally as effective as linear methods in terms of performance. Our findings have important implications for the field of computer vision and can inform future research in this area.

% This chapter contains the concluding remarks of the project. It is based on the discussion in chapter \ref{cha:discussion}, the results from chapter \ref{cha:results} and the problem statement in section \ref{sec:problem-statement}. The chapter concludes with a reflection and perspectives for future work.