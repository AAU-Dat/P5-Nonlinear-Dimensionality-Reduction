\section{Future works}

There are several potential directions for interesting future work based on the results of this project. One possibility would be to explore the performance of other machine learning models, such as decision trees, random forests, or neural networks, in combination with different dimensionality reduction techniques. Another interesting direction would be to investigate the impact of different kernel functions on the performance of nonlinear dimensionality reduction methods, such as kernel principal component analysis (KPCA) or Isomap. Additionally, it would be interesting to explore the use of dimensionality reduction for other types of data, such as text or audio data, and compare the effectiveness of different techniques in these contexts. Finally, further research could be done to investigate the relationship between sample size, dimensionality, and the performance of dimensionality reduction methods, in order to better understand the factors that influence the effectiveness of these techniques.