\section{The moral of the story}\label{sec:moral-of-the-story}
To wrap the discussion up, the group will present the insights they have gained from the project. 
%What it should be used for
%It takes lesser time, which is good for the UN since it is eco-friendly
%It is a tool that can be used to reduce the time needed to train a model
%Make a reference to Christoffer's project, a case where this could be used
%What other things did we learn?
%We also learned that lda was bad...


%Go through the experiments one-by-one and conclude from them what we learned

The project can serve as a tool. The data samples that were worked with were primarily because the nonlinear methods recquired a lot of RAM, and because it clearly took longer time to reduce the dimensions. Through the experiments shown in the Section \textbf{results}, it was highlighted that increasing the data size by 300\% did not drastically increase the model's accuracy. Such technique of trying to incrementally improving the \gls{ml} model might be significant, but the scope of the project was not to design a state-of-the-art \gls{ml} model, but to investigate the effect of dimensionality reduction on the \gls{ml} model. Therefore, if the data size, time consumption, or hardware limitations are not a concern, then the project can be run on the full dataset. There are also more hyperparameters that can be added to the cross-validation, which were left out due to the time constraints, and the fact that hyperparameter optimization was not the focus of the project.


Another thing that the group learned is that the model's performance was better without dimensionality reduction. The interesting part is that dimensionality reduction has shown to be effective because it reduced the time for the model to learn from the data, and the drop in accuracy was only about 2\%. Such finding could serve as further inspiration for future research, as the time needed to train the model and still achieve a high accuracy is a victory, as far as the project is concerned with the \gls{mnist} data set. More research could be done regarding other data sets, and potentially other dimensionality reduction techniques, and \gls{ml} models.




