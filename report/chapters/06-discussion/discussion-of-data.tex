\section{The effect of the dataset}\label{sec:discussion-of-data}
Based on the results presented in Table \ref{tab:discussion-experiment-1-accuracy}, and \ref{sec:experiments} the diskussion it appears that the \gls{mnist} dataset is somewhat well-suited for running both linear and nonlinear dimensionality reduction methods.  

In general, the nonlinear dimensionality reduction methods performed similarly to the linear methods in terms of accuracy. \gls{kpca} had the highest accuracy, but it was slower to train compared to the linear methods. \gls{isomap} had a lower accuracy than the linear methods, but it was also slower to train. Overall, the results support the hypothesis that nonlinear dimensionality reduction methods work as well as linear methods on the \gls{mnist} dataset.

It is on the other hand possible that using a different dataset could have resulted in different conclusions regarding the performance of linear and nonlinear dimensionality reduction methods. The characteristics of the dataset, such as the number of data samples and the complexity of the data, can affect the performance of the different methods. For example, if the dataset has a larger number of data samples or is more complex, the nonlinear methods may outperform the linear methods in terms of accuracy. On the other hand, if the dataset is small or simple, the linear methods may perform better. Therefore, using a different dataset may have altered our conclusions about the performance of linear and nonlinear methods.

If the \gls{cifar} or \gls{fashion-mnist} datasets had been used instead of the \gls{mnist} dataset, the results and conclusions regarding the performance of linear and nonlinear dimensionality reduction methods may have been different. Both the \gls{cifar} and \gls{fashion-mnist} datasets are more complex than the \gls{mnist} dataset, with more data samples and more classes to classify. In general, nonlinear methods tend to perform better on complex and high-dimensional datasets compared to linear methods. Therefore, it is likely that the nonlinear dimensionality reduction methods would have outperformed the linear methods in terms of accuracy on the \gls{cifar} or \gls{fashion-mnist} datasets. This could have led to different conclusions about the performance of linear and nonlinear methods.

It was also discussed the potential impact of using a different dataset on the performance of linear and nonlinear dimensionality reduction methods. The characteristics of the dataset, such as the number of data samples and the complexity of the data, can affect the performance of the different methods. Using a more complex and high-dimensional dataset may have led to different conclusions about the performance of linear and nonlinear methods. In conclusion, the \gls{mnist} dataset is well-suited for testing dimensionality reduction methods, and the results support the hypothesis that nonlinear dimensionality reduction methods work as well as linear methods on the \gls{mnist} dataset.