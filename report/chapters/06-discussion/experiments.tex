\section{Hypothesis Testing} \label{sec:experiments}
This section will discuss the experiments we ran to test our hypothesis. The experiments will be discussed in the following order: Experiment 1, Experiment 2, Experiment 3, and Experiment 4. The hypothesis for the project is that nonlinear methods will not be able to outperform linear methods. Running experiments tested this hypothesis to see if the hypothesis held. 

Each experiment has been conducted with a different purpose. Experiment 1 tested the hypothesis by comparing the linear methods' performance to the nonlinear methods' performance. Experiment 2 tested the number of components before a significant drop-off in the accuracy score. Experiment 3 tested the influence kernels have on the accuracy score. Experiment 4 tested the hypothesis on different sample sizes and how the dimensionality reduction methods grew with the number of samples and checked the differences between the dimensionality reduction scaled with the different numbers of samples.

The result from experiment~\ref{sec:experiment-1} shows that \gls{lda} is the fastest method, followed by \gls{pca}, \gls{kpca}, and \gls{isomap}. This was expected as \gls{lda} and \gls{pca} are linear methods, and \gls{kpca} is a linear method with a nonlinear kernel, making it more computationally expensive. \gls{isomap} is also a nonlinear method and therefore expected to be slower than both linear methods. By knowing \gls{pca} and \gls{kpca} is similar, their accuracy scores would be similar. This was expected, as \gls{pca} and \gls{kpca} are both linear methods, and the only difference is the kernel. \gls{isomap} should be close in accuracy score, as it is a nonlinear method, but it could have been more accurate than expected, as it is a more complex method. \gls{lda} was the least accurate method, as it is a linear method, which was unexpected as it was expected to be one of the most accurate methods. The drop from \gls{pca} and \gls{kpca} to \gls{isomap} and \gls{lda} was more significant, as the methods were displayed with their best side. By looking at the overall accuracy score, the results in the hypothesis need to be corrected, as the nonlinear methods did outperform the linear methods, as they had a higher accuracy score. The time it takes to run the methods was also tested, and the result shows that \gls{lda} is the fastest method, followed by \gls{pca}, \gls{kpca}, and last, \gls{isomap}. This was expected as \gls{lda} and \gls{pca} are linear methods, and \gls{kpca} is a linear method with a nonlinear kernel, making it more computationally expensive. \gls{isomap} is also a nonlinear method and expects to be slower than both linear methods.


The result from experiment~\ref{sec:experiment-2} shows that the number of components that can remove before the highest accuracy score drops by 1\% is 0 for \gls{lda}, 31 for \gls{pca} and \gls{kpca}, and 20 for \gls{isomap}. \gls{isomap} and \gls{kpca} expect to be very robust as they are both nonlinear methods, taking more components to drop a percentage. \gls{lda} is a linear method and expects a quick drop-off in the accuracy score. \gls{pca} expected a quick drop-off in the accuracy score, as it is a linear method. However, as \gls{pca} and \gls{kpca} are similar, it was expected that both could have a similar number of components removed before a significant drop-off in the accuracy score. The result shows that the nonlinear methods are more robust, as they can remove more components before a significant drop-off in the accuracy score. This also does not hold for the hypothesis, as the nonlinear methods outperformed the experiment's linear methods. Had time been a significant factor for the project other than comparing the different methods, it would have been considered to run the models on a machine with more memory. A machine with more memory could also have allowed running more models on the same machine, which would have been beneficial for comparing the different methods. The machines used for this project did not have the same CPU power. Therefore it could have been beneficial to use a single powerful machine to run all the models. A single powerful machine would have reduced the time to fit the models and allowed more precise comparisons between the different methods.

The result from experiment~\ref{sec:experiment-3} shows that the accuracy score is the highest for \gls{pca}, then the sigmoid kernel, followed by the RBF kernel. The hypothesis says that \gls{pca} would outperform the other methods, as it is the linear method in the experiment. Therefore the result withholds the hypothesis as the nonlinear methods, the sigmoid and RBF kernels, did not outperform the linear methods in the experiment. 

The result from experiment~\ref{sec:experiment-4} shows that the methods each grow linearly with the number of samples. This was expected, as \gls{pca} and \gls{lda} are linear and expected to grow linearly with the number of samples. \gls{isomap} and \gls{kpca} are the slowest methods, as they are nonlinear and expected to be slower than the linear methods. The result holds for the hypothesis, as the nonlinear methods did not outperform linear ones. This is not surprising, as the nonlinear methods are more computationally expensive, and the data could be more complex.

The results from the experiments show that the hypothesis is correct, as the nonlinear methods did not outperform the linear methods. The dataset used by MNIST is specific; therefore, another dataset can be used to test the hypothesis. 



%The results are shown in table \ref{tab:experiments}. The results show that the hypothesis is correct, as the non-linear methods did not outperform the linear methods. This is not surprising, as the data is not very complex, and the non-linear methods are not very complex either. The non-linear methods are also more computationally expensive, which is why we did not use them in the final implementation. 



%summery of experiments (linear vs non-linear)