\section{Discussion of experiments} \label{sec:experiments}
This section will discuss the experiments we ran to compare the dimensionality reduction techniques. The experiments will be discussed in order from 1 to 4.

Each experiment has been conducted with a different purpose. Experiment 1 compared the linear methods' performance to the nonlinear methods' performance in regards to errors, time and F1 score. Experiment 2 tested the number of components before a significant drop-off in the accuracy score. Experiment the two kernels in \gls{kpca}. Experiment 4 compared how sample size affects the score of each dimensionality reduction method, to determine if some methods are more or less reliant on data.


\subsubsection{Experiment 1}\label{subsec:experiment-1}
In the first experiment, the \autoref{tab:discussion-experiment-1-accuracy} shows that at 15 thousand samples \gls{pca} and \gls{lda} are the fastest, with \gls{pca} being a little slower, but with higher accuracy. The lower accuracy to be expected as \gls{lda} performs a much larger reduction of dimensionality, and the difference in time is also to be expected as linear methods are typically faster than nonlinear methods.

Comparing \gls{kpca} at 15 thousand samples, and \gls{pca} at 60 thousand samples, it can be seen that they are similar in both time and accuracy, with \gls{pca} having gained only a small amount of additional accuracy despite quadrupling the amount of samples compared to the 15 thousand sample run.

\gls{isomap} is by far the slowest method and has lower accuracy than both \gls{pca} and \gls{kpca}, being $\approx$3\% more accurate than \gls{lda} but taking $\approx$23 times longer to run. It is unlikely that \gls{isomap} would be a good choice for this dataset, as it is slower than all the other methods, and less accurate than all but \gls{lda}.

From this experiment it seems that \gls{mnist} is not nonlinear enough to benefit from \gls{isomap} and \gls{kpca}, but \gls{kpca} still has potential. However, because the \gls{svm} model does so well even before dimensionality reduction it may be that the advantages of any nonlinear approach are lost in the \gls{mnist} dataset. This is further supported by the fact that no method is able to reach the accuracy of the \gls{svm} model, even with 60 thousand samples. This is likely because the \gls{svm} model is already able to find the nonlinear relationships in the data, and the methods are not able to improve on this.


\subsubsection{Experiment 2}\label{subsec:experiment-2}
From the results of the second experiment in \autoref{tab:experiment_2_methods_comparison} it can be seen that the stability of the methods are vastly different. \gls{lda} is the most accurate method at low dimensions, and retains its accuracy relative to itself even at very low dimensions. \gls{isomap} however is the most stable method, retaining its accuracy relative to itself at as little as 20 dimensions - the difference between 50 dimensions and 20 dimensions is only 1\%, suggesting that \gls{isomap} is able to find some nonlinear relationships in the data that \gls{pca} and \gls{kpca} are not able to find.

\gls{pca} and \gls{kpca} are less stable in relative accuracy than \gls{lda} at low dimensions, but does well at higher dimensions. This is to be expected, as the linear approach will always have a certain amount of data loss that scales directly with the number of linearly important dimensions.

Lastly, \gls{lda} and \gls{isomap} are almost equal in terms of accuracy at 9 dimensions, possibly suggesting that the data is not nonlinear enough to benefit from \gls{isomap}, or that the data is linear enough at this level of dimensionality that \gls{isomap} is not able to find any nonlinear relationships.

\todo[inline]{Generally I'm missing a lot of actual accuracy values in the results section. It would be nice to know what the accuracies actually are.}


\subsubsection{Experiment 3}\label{subsec:experiment-3}
The results from experiment 3 suggest that generally a sigmoid kernel performs better than a \gls{rbf} kernel on \gls{mnist}. Both kernels give similar results at low dimensions as seen in experiment 2, but the sigmoid kernel performs better in general. Further testing would be needed to determine if this is a general trend for \gls{mnist}, or if the results are specific to this particular run, but it is expected to be a general trend.

Interestingly, the kernels performed their best at different gamma values. Where the sigmoid kernel did best at $\gamma = 0.01$, the \gls{rbf} kernel did best at $\gamma = 0.001$. The \gls{rbf} kernel performed abysmally at $\gamma = 0.01$, and the sigmoid kernel performed more or less as well at $\gamma = 0.001$. This result showcases the importance of performing hyperparameter tuning.

The \gls{rbf} kernel is considered a good default kernel~\cite{scikit-learn}. However for \gls{mnist} \gls{rbf} seems to be less accurate than a sigmoid kernel. This suggests that the kernels are not interchangeable, and that the best kernel for a given dataset is not necessarily the same as the best kernel for another dataset.

Because this experiment only compared two kernels, it is possible that there are other kernels that perform better than both of these. Further testing would be needed to determine if this is the case, but based on the previous experiments it is not expected to that there are any kernels that perform better than the sigmoid kernel for \gls{mnist}. This is because the sigmoid kernel performed close to the \gls{svm} model and \gls{pca}.


\subsubsection{Experiment 4}\label{subsec:experiment-4}
Experiment 4 shows that \gls{lda} and \gls{pca} scales the best with the number of samples for time, followed by \gls{kpca} and \gls{isomap}. This was expected as \gls{lda} and \gls{pca} are both linear methods, while \gls{kpca} and \gls{isomap} are nonlinear methods, making them more computationally complex and expensive. It was also expected and shown that \gls{kpca} is faster than \gls{isomap}.

\gls{pca} and \gls{lda} seem to scale linearly with the number of samples for time, while \gls{kpca} and \gls{isomap} seem to scale exponentially\todo{Correct this to match Gustavs new results} with the number of samples. This is somewhat expected, as the kernel trick applied for \gls{kpca} scales quadratically with the number of samples, and \gls{isomap} is a nonlinear method that builds graphs of the data, which scales with both sample size and dimensionality.

When looking at accuracy of the models, each method scales with the number of samples, which is, of course, expected, and there does not seem to be any method that requires more samples to perform well than the others. However it can be observed that \gls{lda} performs worse with more data between 400 and 800 samples, and then increases again to match the trend. We do not know why this dip in accuracy happens, but it is likely an error to do with the amount of data required in \gls{lda}.




\subsubsection{Summary of experiments}\label{subsec:summary-of-experiments}
%summary of experiments (linear vs non-linear)
