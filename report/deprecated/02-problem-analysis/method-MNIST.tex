\section{Used methods in MNIST}\label{sec:method-MNIST}
\todo[inline]{Unfinished section}
When comparing the results of projects using the MNIST dataset, it is important to know which feature engineering and classification methods were used. In this section, we will describe the methods used in the projects that we have analyzed.

On the MNIST webcite \cite{MNIST} there is a tabel of all the official methods used on the MNIST dataset with the last posted in 2012. As this project is based on the MNIST data set, the methods used in this project will be compared to some of the methods used on the MNIST dataset. One thing to note, when looking in the table on the MNIST webcite, is there is a column that describes the preprocessing of the data.

This is not the same as the feature engineering, which is the process of extracting features from the data. The preprocessing is the process of cleaning the data, which is done before the feature engineering.

As this project focuses on feature engineering, it is important what feature engineering that has been used on the projects when compairng it to this projects result.

\urgent[inline]{fix table}


\begin{table}[htb!]
    \centering
    \resizebox{1\textwidth}{!}
    {
        \begin{tabular}{|c|c|c|}
            \hline
            Classifier                                                          & Preprocessing       & Test error rate(\%) \\
            \hline
            \multicolumn{3}{|c|}{\textbf{Linear classifiers}}                                                               \\
            \hline
            linear classifier(1-layer NN)                                       & none                & 12.0                \\
            linear classifier(1-layer NN)                                       & deskewing           & 8.4                 \\
            pairwise linear classifier                                          & deskewing           & 7.6                 \\
            \hline
            ...                                                                 & ...                 & ...                 \\
            \hline
            \multicolumn{3}{|c|}{\textbf{Non-linear classifiers}}                                                           \\
            \hline
            40 PCA + quadratic classifier                                       & none                & 3.3                 \\
            1000 RBF + linear classifier                                        & none                & 3.6                 \\
            \hline
            ...                                                                 & ...                 & ...                 \\
            \hline
            \multicolumn{3}{|c|}{\textbf{Convolutional nets}}                                                               \\
            \hline
            committee of 35 conv. net, 1-20-P-40-P-150-10 [elastic distortions] & width normalization & 0.23                \\
            \hline
        \end{tabular}
    }
    \caption{The methods previusly used on the MNIST data set}
    \label{tab:method-MNIST}
\end{table}


There are not many projects that use feature engineering on the MNIST dataset as seen here \cite{Stochastic-optimization-neural-networks-assiri, BYERLY2021545, convolutional-neural-networks-convnets, multi-column-neural-network-ciregan, WaveMix-jeevan}. These only use a specific machine learning model, with the raw data from MNIST, so there is no feature engineering on them. Therefore we can not fully compare our results, as the projects are researching different models to get the best outcome where this project is researching different feature engineering methods to get the best outcome.

Some of the results from the projects are shown in Table \ref{tab:method-MNIST}.
In Table \ref{tab:method-MNIST} there is the linear classifiers, specificly the one with none preprocessed data, that has an error rate of 12.0\% which would be the one closest to this project.

In the Table \ref{tab:method-MNIST} there is also the non-linear classifiers, both of them has not have any preprocessed data, which both could be compared to the result this projects model will get. The first one is the PCA + quadratic classifier with an error rate of 3.3\% and the second one is the RPF + linear classifier with an error rate of 3.6\%.

On the MNIST webcite \cite{MNIST} the project with the lowest error procentage is the Committee of 35 conv. net, 1-20-P-40-P-150-10 [elastic distortions] by Dan Cire≈üan, Ueli Meier and Juergen Schmidhuberthe, this was done with preprocessed data by width normalization and a error rate of 0.23\%.
